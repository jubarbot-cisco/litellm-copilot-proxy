model_list:
  - model_name: gpt-5-mini
    litellm_params:
      model: github_copilot/gpt-5-mini
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5 mini (Azure OpenAI) - enabled
    # Max tokens: 64000, Context: 264000

  - model_name: gpt-5
    litellm_params:
      model: github_copilot/gpt-5
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5 (Azure OpenAI) - enabled
    # Max tokens: 128000, Context: 400000

  - model_name: gpt-4o-mini-2024-07-18
    litellm_params:
      model: github_copilot/gpt-4o-mini-2024-07-18
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o mini (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

  - model_name: gpt-4o-2024-11-20
    litellm_params:
      model: github_copilot/gpt-4o-2024-11-20
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o (Azure OpenAI) - enabled
    # Max tokens: 16384, Context: 128000

  - model_name: gpt-4o-2024-08-06
    litellm_params:
      model: github_copilot/gpt-4o-2024-08-06
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o (Azure OpenAI) - enabled
    # Max tokens: 16384, Context: 128000

  - model_name: gpt-5.1
    litellm_params:
      model: github_copilot/gpt-5.1
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5.1 (OpenAI) - enabled
    # Max tokens: 64000, Context: 264000

  - model_name: gpt-5-codex
    litellm_params:
      model: github_copilot/gpt-5-codex
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-5-Codex (Preview) (OpenAI) - enabled
    # Max tokens: 128000, Context: 400000

  - model_name: claude-sonnet-4
    litellm_params:
      model: github_copilot/claude-sonnet-4
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Sonnet 4 (Anthropic) - enabled
    # Max tokens: 16000, Context: 216000

  - model_name: claude-sonnet-4.5
    litellm_params:
      model: github_copilot/claude-sonnet-4.5
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Sonnet 4.5 (Anthropic) - enabled
    # Max tokens: 16000, Context: 144000

  - model_name: claude-opus-4.5
    litellm_params:
      model: github_copilot/claude-opus-4.5
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Opus 4.5 (Anthropic) - enabled
    # Max tokens: 16000, Context: 160000

  - model_name: claude-haiku-4.5
    litellm_params:
      model: github_copilot/claude-haiku-4.5
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # Claude Haiku 4.5 (Anthropic) - enabled
    # Max tokens: 16000, Context: 144000

  - model_name: gemini-3-pro-preview
    litellm_params:
      model: github_copilot/gemini-3-pro-preview
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # Gemini 3 Pro (Preview) (Google) - enabled
    # Max tokens: 64000, Context: 128000

  - model_name: gemini-2.5-pro
    litellm_params:
      model: github_copilot/gemini-2.5-pro
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # Gemini 2.5 Pro (Google) - enabled
    # Max tokens: 64000, Context: 128000

  - model_name: gpt-4.1-2025-04-14
    litellm_params:
      model: github_copilot/gpt-4.1-2025-04-14
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4.1 (Azure OpenAI) - enabled
    # Max tokens: 16384, Context: 128000

  - model_name: gpt-3.5-turbo-0613
    litellm_params:
      model: github_copilot/gpt-3.5-turbo-0613
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 3.5 Turbo (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 16384

  - model_name: gpt-4
    litellm_params:
      model: github_copilot/gpt-4
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 4 (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 32768

  - model_name: gpt-4-0613
    litellm_params:
      model: github_copilot/gpt-4-0613
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 4 (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 32768

  - model_name: gpt-4-0125-preview
    litellm_params:
      model: github_copilot/gpt-4-0125-preview
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 4 Turbo (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

  - model_name: gpt-4o-2024-05-13
    litellm_params:
      model: github_copilot/gpt-4o-2024-05-13
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

  - model_name: gpt-4-o-preview
    litellm_params:
      model: github_copilot/gpt-4-o-preview
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

  - model_name: gpt-4.1
    litellm_params:
      model: github_copilot/gpt-4.1
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4.1 (Azure OpenAI) - enabled
    # Max tokens: 16384, Context: 128000

  - model_name: gpt-3.5-turbo
    litellm_params:
      model: github_copilot/gpt-3.5-turbo
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 3.5 Turbo (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 16384

  - model_name: gpt-4o-mini
    litellm_params:
      model: github_copilot/gpt-4o-mini
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o mini (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

  - model_name: gpt-4
    litellm_params:
      model: github_copilot/gpt-4
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT 4 (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 32768

  - model_name: gpt-4o
    litellm_params:
      model: github_copilot/gpt-4o
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

  - model_name: gpt-4-o-preview
    litellm_params:
      model: github_copilot/gpt-4-o-preview
      extra_headers: {"Editor-Version": "vscode/1.107.0", "Copilot-Integration-Id": "vscode-chat"}
    # GPT-4o (Azure OpenAI) - enabled
    # Max tokens: 4096, Context: 128000

